2022-10-07 00:03:20.699  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:08:20.734  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:13:20.743  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:18:20.746  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:18:44.395  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.m.d.connection                         : Opened connection [connectionId{localValue:5, serverValue:39}] to localhost:27017
2022-10-07 00:18:44.395  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:38}] to localhost:27017
2022-10-07 00:18:44.408  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-6] o.m.d.connection                         : Opened connection [connectionId{localValue:6, serverValue:40}] to localhost:27017
2022-10-07 00:18:44.409  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-7] o.m.d.connection                         : Opened connection [connectionId{localValue:7, serverValue:41}] to localhost:27017
2022-10-07 00:18:44.420  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-8] o.m.d.connection                         : Opened connection [connectionId{localValue:8, serverValue:42}] to localhost:27017
2022-10-07 00:18:44.421  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-9] o.m.d.connection                         : Opened connection [connectionId{localValue:9, serverValue:43}] to localhost:27017
2022-10-07 00:20:51.675  INFO LAPTOP-LTI5PG0G --- [ctor-http-nio-2] r.M.O.1                                  : onSubscribe(FluxOnErrorResume.ResumeSubscriber)
2022-10-07 00:20:51.677  INFO LAPTOP-LTI5PG0G --- [ctor-http-nio-2] r.M.O.1                                  : request(unbounded)
2022-10-07 00:20:53.605  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] n.g.c.o.s.i.KafkaProducerService         : Producing message MasterAccountModel(id=d40c89e0-2651-406b-b26f-8728af9094ee, numberAccount=1234567809, type=TypeModel(code=AHO3, description=Plazo fijo: libre de comisión por mantenimiento, solo permite un movimiento de retiro o depósito en un día específico del mes., status=A, countLimitOperation=0, amountCommission=0.0, countPerson=99999, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), startDate=2022.10.6 10.20.0, status=A, endDate=null, amount=250.5, coinType=PEN)
2022-10-07 00:20:53.619  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.p.ProducerConfig                 : ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2022-10-07 00:20:53.643  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.p.KafkaProducer                  : [Producer clientId=producer-1] Instantiated an idempotent producer.
2022-10-07 00:20:53.671  WARN LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.p.ProducerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 00:20:53.672  WARN LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.p.ProducerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 00:20:53.672  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 00:20:53.672  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 00:20:53.672  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665120053672
2022-10-07 00:20:53.688  INFO LAPTOP-LTI5PG0G --- [ad | producer-1] o.a.k.c.Metadata                         : [Producer clientId=producer-1] Resetting the last seen epoch of partition account-topic-0 to 0 since the associated topicId changed from null to a_hxx4ZBRuGupSvNB22i8g
2022-10-07 00:20:53.689  INFO LAPTOP-LTI5PG0G --- [ad | producer-1] o.a.k.c.Metadata                         : [Producer clientId=producer-1] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 00:20:53.694  INFO LAPTOP-LTI5PG0G --- [ad | producer-1] o.a.k.c.p.i.TransactionManager           : [Producer clientId=producer-1] ProducerId set to 1001 with epoch 0
2022-10-07 00:20:53.720  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] r.M.O.1                                  : onNext(<201 CREATED Created,{typeAccount=TypeModel(code=AHO3, description=Plazo fijo: libre de comisión por mantenimiento, solo permite un movimiento de retiro o depósito en un día específico del mes., status=A, countLimitOperation=0, amountCommission=0.0, countPerson=99999, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), account=MasterAccountModel(id=d40c89e0-2651-406b-b26f-8728af9094ee, numberAccount=1234567809, type=TypeModel(code=AHO3, description=Plazo fijo: libre de comisión por mantenimiento, solo permite un movimiento de retiro o depósito en un día específico del mes., status=A, countLimitOperation=0, amountCommission=0.0, countPerson=99999, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), startDate=2022.10.6 10.20.0, status=A, endDate=null, amount=250.5, coinType=PEN)},[Location:"/operation/account/bank"]>)
2022-10-07 00:20:53.751  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] r.M.O.1                                  : onComplete()
2022-10-07 00:23:20.760  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:25:34.172  INFO LAPTOP-LTI5PG0G --- [ctor-http-nio-2] r.M.O.2                                  : onSubscribe(FluxOnErrorResume.ResumeSubscriber)
2022-10-07 00:25:34.172  INFO LAPTOP-LTI5PG0G --- [ctor-http-nio-2] r.M.O.2                                  : request(unbounded)
2022-10-07 00:25:34.274  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] n.g.c.o.s.i.KafkaProducerService         : Producing message MasterAccountModel(id=9373076c-096d-440b-b371-3947e5b84046, numberAccount=33333333333, type=TypeModel(code=AHO1, description=Ahorro: libre de comisión por mantenimiento y con un límite máximo de movimientos mensuales., status=A, countLimitOperation=10, amountCommission=0.0, countPerson=1, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), startDate=2022.10.7 14.10.0, status=A, endDate=null, amount=420.5, coinType=PEN)
2022-10-07 00:25:34.276  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] r.M.O.2                                  : onNext(<201 CREATED Created,{typeAccount=TypeModel(code=AHO1, description=Ahorro: libre de comisión por mantenimiento y con un límite máximo de movimientos mensuales., status=A, countLimitOperation=10, amountCommission=0.0, countPerson=1, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), account=MasterAccountModel(id=9373076c-096d-440b-b371-3947e5b84046, numberAccount=33333333333, type=TypeModel(code=AHO1, description=Ahorro: libre de comisión por mantenimiento y con un límite máximo de movimientos mensuales., status=A, countLimitOperation=10, amountCommission=0.0, countPerson=1, countBusiness=0, amountStart=0.0, codeRequired=null, maintenanceCommission=null, product=null), startDate=2022.10.7 14.10.0, status=A, endDate=null, amount=420.5, coinType=PEN)},[Location:"/operation/account/bank"]>)
2022-10-07 00:25:34.280  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-5] r.M.O.2                                  : onComplete()
2022-10-07 00:28:20.775  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:29:53.773  INFO LAPTOP-LTI5PG0G --- [ad | producer-1] o.a.k.c.NetworkClient                    : [Producer clientId=producer-1] Node -1 disconnected.
2022-10-07 00:33:20.788  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:38:20.793  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:43:20.809  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:48:20.816  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:53:20.823  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 00:55:37.633  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Disconnecting from node 0 due to request timeout.
2022-10-07 00:55:37.634  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cancelled in-flight FETCH request with correlation id 9826 due to node 0 being disconnected (elapsed time since creation: 45813ms, elapsed time since send: 45812ms, request timeout: 30000ms)
2022-10-07 00:55:37.633  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.exceptionCaught(NettyStream.java:427)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:302)
	at io.netty.channel.AbstractChannelHandlerContext.invokeExceptionCaught(AbstractChannelHandlerContext.java:281)
	at io.netty.channel.AbstractChannelHandlerContext.fireExceptionCaught(AbstractChannelHandlerContext.java:273)
	at com.mongodb.connection.netty.NettyStream$ReadTimeoutTask.run(NettyStream.java:564)
	at io.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
	at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:153)
	at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:503)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.timeout.ReadTimeoutException
2022-10-07 00:55:37.635  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.FetchSessionHandler              : [Consumer clientId=consumer-group_json-1, groupId=group_json] Error sending fetch request (sessionId=97174772, epoch=7415) to node 0:
org.apache.kafka.common.errors.DisconnectException
2022-10-07 00:55:37.637  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-10-07 00:55:37.637  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Requesting disconnect from last known coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 00:55:37.638  INFO LAPTOP-LTI5PG0G --- [ad | group_json] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Client requested disconnect from node 2147483647
2022-10-07 00:55:37.649  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:10, serverValue:58}] to localhost:27017
2022-10-07 00:55:37.651  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=7308000}
2022-10-07 00:55:37.707  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 00:55:37.782  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Attempt to heartbeat with Generation{generationId=8, memberId='consumer-group_json-1-5949b128-56ac-4eea-9ec0-1164aa28f607', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-10-07 00:55:37.783  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting generation due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 00:55:37.783  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: encountered UNKNOWN_MEMBER_ID from HEARTBEAT response
2022-10-07 00:55:37.784  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-10-07 00:55:37.784  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Lost previously assigned partitions Kafka_target-0
2022-10-07 00:55:37.785  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions lost: [Kafka_target-0]
2022-10-07 00:55:37.785  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions revoked: [Kafka_target-0]
2022-10-07 00:55:37.785  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 00:55:37.800  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 00:55:37.801  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 00:55:37.966  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=11, memberId='consumer-group_json-1-6e87477e-09cf-498c-a699-0cf507844d29', protocol='range'}
2022-10-07 00:55:38.223  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=11, memberId='consumer-group_json-1-6e87477e-09cf-498c-a699-0cf507844d29', protocol='range'}
2022-10-07 00:55:38.225  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 00:55:38.226  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 00:55:38.234  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 00:55:38.235  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 00:59:06.584  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:04:06.599  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:09:06.609  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:14:06.624  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:14:55.829  INFO LAPTOP-LTI5PG0G --- [tLoopGroup-3-11] o.m.d.connection                         : Opened connection [connectionId{localValue:11, serverValue:63}] to localhost:27017
2022-10-07 01:14:55.893  INFO LAPTOP-LTI5PG0G --- [tLoopGroup-3-12] o.m.d.connection                         : Opened connection [connectionId{localValue:12, serverValue:64}] to localhost:27017
2022-10-07 01:18:51.835 ERROR LAPTOP-LTI5PG0G --- [tLoopGroup-3-12] a.w.r.e.AbstractErrorWebExceptionHandler : [9401da46-5]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint ? Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint ? HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxSwitchIfEmpty$SwitchIfEmptySubscriber.onNext(FluxSwitchIfEmpty.java:74)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 01:19:06.639  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:24:06.640  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:29:06.657  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:34:06.666  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:39:15.988  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 01:39:17.655  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 01:39:21.236  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 01:39:21.239  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 01:39:21.248  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 01:39:22.467  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 01:39:22.571  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 98 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 01:39:22.955  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 01:39:23.059  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:39:23.061  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:39:23.063  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:39:24.747  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@8851ec, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@18b40fe6], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7198ab9a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@67d5ac2f], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 01:39:24.873  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:39:25.076  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:39:26.856  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:72}] to localhost:27017
2022-10-07 01:39:26.856  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:71}] to localhost:27017
2022-10-07 01:39:26.858  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=76340000}
2022-10-07 01:39:29.101  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 01:39:30.449  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 01:39:30.539  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 01:39:30.616  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 01:39:30.677  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 01:39:30.682  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:39:30.711  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 01:39:30.711  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 01:39:30.712  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 01:39:30.712  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 01:39:30.712  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 01:39:30.712  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 01:39:30.712  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 01:39:31.053  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 01:39:31.057  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 01:39:31.061  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 01:39:31.066  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665124771065 with initial instances count: 5
2022-10-07 01:39:31.068  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 01:39:31.068  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665124771068, current=UP, previous=STARTING]
2022-10-07 01:39:31.071  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 01:39:31.123  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 01:39:31.128  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 01:39:31.246  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 01:39:31.246  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 01:39:31.248  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 01:39:31.248  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 01:39:31.248  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665124771246
2022-10-07 01:39:31.254  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 01:39:31.383  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 01:39:31.385  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 01:39:32.053  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 01:39:32.058  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 01:39:32.062  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 01:39:32.068  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 01:39:32.097  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 01:39:32.098  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 01:39:33.891  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 19.563 seconds (JVM running for 20.851)
2022-10-07 01:39:38.895  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=12, memberId='consumer-group_json-1-3b352915-e073-4ad0-a794-a21d44721432', protocol='range'}
2022-10-07 01:39:38.921  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=12, memberId='consumer-group_json-1-3b352915-e073-4ad0-a794-a21d44721432', protocol='range'}
2022-10-07 01:39:38.933  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 01:39:38.940  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 01:39:38.965  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 01:39:38.968  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 01:40:00.268  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:73}] to localhost:27017
2022-10-07 01:40:00.529  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:74}] to localhost:27017
2022-10-07 01:40:00.569 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] a.w.r.e.AbstractErrorWebExceptionHandler : [f59e0ff5-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint ? Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint ? HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmit(FluxFlatMap.java:543)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:984)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 01:42:29.114  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 01:42:30.656  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 01:42:41.677  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 01:42:41.679  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 01:42:41.689  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 01:42:43.050  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 01:42:43.155  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 99 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 01:42:43.545  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 01:42:43.642  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:42:43.645  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:42:43.648  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:42:45.361  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 01:42:45.475  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:42:45.682  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:42:47.485  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:75}] to localhost:27017
2022-10-07 01:42:47.485  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:76}] to localhost:27017
2022-10-07 01:42:47.487  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=73838300}
2022-10-07 01:42:49.886  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 01:42:51.660  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 01:42:51.780  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 01:42:51.862  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 01:42:51.910  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 01:42:51.917  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:42:51.943  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 01:42:51.944  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 01:42:51.945  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 01:42:51.946  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 01:42:51.946  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 01:42:51.946  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 01:42:51.947  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 01:42:52.270  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 01:42:52.274  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 01:42:52.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 01:42:52.287  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665124972285 with initial instances count: 5
2022-10-07 01:42:52.289  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 01:42:52.290  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665124972289, current=UP, previous=STARTING]
2022-10-07 01:42:52.293  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 01:42:52.337  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 01:42:52.344  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 01:42:52.432  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 01:42:52.433  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 01:42:52.435  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 01:42:52.435  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 01:42:52.435  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665124972433
2022-10-07 01:42:52.439  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 01:42:52.526  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 01:42:52.527  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 01:42:52.828  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 01:42:52.830  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 01:42:52.832  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 01:42:52.836  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 01:42:52.852  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 01:42:52.853  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 01:42:54.460  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=13, memberId='consumer-group_json-1-d9b583be-4ead-4bac-aa2c-8b7327a56c6a', protocol='range'}
2022-10-07 01:42:54.511  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=13, memberId='consumer-group_json-1-d9b583be-4ead-4bac-aa2c-8b7327a56c6a', protocol='range'}
2022-10-07 01:42:54.516  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 01:42:54.521  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 01:42:54.536  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 01:42:54.537  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 01:42:54.803  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 27.206 seconds (JVM running for 28.138)
2022-10-07 01:43:58.607  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:77}] to localhost:27017
2022-10-07 01:43:58.798  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-4] o.m.d.connection                         : Opened connection [connectionId{localValue:4, serverValue:78}] to localhost:27017
2022-10-07 01:43:58.862 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [29ae92fa-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint ? Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint ? HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drainLoop(FluxFlatMap.java:712)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.drain(FluxFlatMap.java:588)
		at reactor.core.publisher.FluxFlatMap$FlatMapInner.onNext(FluxFlatMap.java:971)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1798)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoUsingWhen$MonoUsingWhenSubscriber.deferredComplete(MonoUsingWhen.java:268)
		at reactor.core.publisher.FluxUsingWhen$CommitInner.onComplete(FluxUsingWhen.java:527)
		at reactor.core.publisher.Operators.complete(Operators.java:137)
		at reactor.core.publisher.MonoEmpty.subscribe(MonoEmpty.java:46)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onComplete(FluxUsingWhen.java:384)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onComplete(Operators.java:2058)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1817)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onNext(MonoFlatMap.java:151)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$9(OperationExecutorImpl.java:124)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$exceptionTransformingCallback$23(CommandOperationHelper.java:637)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$11(MixedBulkWriteOperation.java:467)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:84)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.async.function.LoopState.breakAndCompleteIf(LoopState.java:111)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$10(MixedBulkWriteOperation.java:418)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:82)
		at com.mongodb.internal.async.function.AsyncCallbackLoop$LoopingCallback.onResult(AsyncCallbackLoop.java:61)
		at com.mongodb.internal.operation.MixedBulkWriteOperation.lambda$executeBulkWriteBatchAsync$9(MixedBulkWriteOperation.java:440)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 01:47:51.951  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:51:52.867  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.NetworkClient                    : [Consumer clientId=consumer-group_json-1, groupId=group_json] Node -1 disconnected.
2022-10-07 01:52:51.968  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:57:51.971  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 01:59:44.666  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 01:59:46.320  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 01:59:51.882  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 01:59:51.884  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 01:59:51.895  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 01:59:53.285  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 01:59:53.397  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 105 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 01:59:53.800  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 01:59:53.905  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:59:53.908  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:59:53.910  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 01:59:55.574  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 01:59:55.734  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:59:55.982  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 01:59:57.836  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:79}] to localhost:27017
2022-10-07 01:59:57.836  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:80}] to localhost:27017
2022-10-07 01:59:57.837  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=83511100}
2022-10-07 02:00:00.318  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:00:01.940  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:00:02.033  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:00:02.117  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:00:02.162  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:00:02.169  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:00:02.193  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:00:02.193  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:00:02.193  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:00:02.194  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:00:02.194  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:00:02.194  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:00:02.194  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:00:02.491  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:00:02.494  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:00:02.499  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:00:02.506  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665126002505 with initial instances count: 5
2022-10-07 02:00:02.508  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:00:02.509  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665126002509, current=UP, previous=STARTING]
2022-10-07 02:00:02.512  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:00:02.566  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:00:02.580  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:00:02.668  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:00:02.669  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:00:02.671  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:00:02.671  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:00:02.672  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665126002669
2022-10-07 02:00:02.675  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:00:02.787  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:00:02.789  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:00:03.172  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:00:03.175  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:00:03.177  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:00:03.180  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:00:03.199  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:00:03.199  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:00:03.293  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:81}] to localhost:27017
2022-10-07 02:00:05.092  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 22.116 seconds (JVM running for 23.083)
2022-10-07 02:00:06.047  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=14, memberId='consumer-group_json-1-faf9eebc-aae7-4edf-933d-a60a237564b7', protocol='range'}
2022-10-07 02:00:06.408  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=14, memberId='consumer-group_json-1-faf9eebc-aae7-4edf-933d-a60a237564b7', protocol='range'}
2022-10-07 02:00:06.416  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:00:06.420  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:00:06.443  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:00:06.445  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:02:24.795  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:02:26.371  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:02:30.299  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:02:30.301  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:02:30.310  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:02:31.646  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:02:31.750  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 96 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:02:32.127  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:02:32.225  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:02:32.227  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:02:32.229  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:02:33.894  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@8851ec, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@18b40fe6], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7198ab9a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@67d5ac2f], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:02:34.013  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:02:34.236  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:02:36.021  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:82}] to localhost:27017
2022-10-07 02:02:36.021  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:83}] to localhost:27017
2022-10-07 02:02:36.022  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=74985400}
2022-10-07 02:02:38.398  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:02:40.042  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:02:40.134  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:02:40.214  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:02:40.249  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:02:40.254  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:02:40.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:02:40.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:02:40.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:02:40.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:02:40.278  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:02:40.279  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:02:40.279  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:02:40.537  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:02:40.540  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:02:40.544  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:02:40.549  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665126160549 with initial instances count: 5
2022-10-07 02:02:40.551  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:02:40.551  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665126160551, current=UP, previous=STARTING]
2022-10-07 02:02:40.553  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:02:40.599  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:02:40.604  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:02:40.681  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:02:40.681  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:02:40.683  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:02:40.684  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:02:40.684  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665126160681
2022-10-07 02:02:40.687  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:02:40.773  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:02:40.775  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:02:41.071  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:02:41.074  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:02:41.076  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:02:41.079  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:02:41.096  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:02:41.097  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:02:43.066  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 19.773 seconds (JVM running for 20.697)
2022-10-07 02:02:48.341  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=15, memberId='consumer-group_json-1-f52ae431-3d90-4049-b147-552300c86618', protocol='range'}
2022-10-07 02:02:48.354  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=15, memberId='consumer-group_json-1-f52ae431-3d90-4049-b147-552300c86618', protocol='range'}
2022-10-07 02:02:48.361  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:02:48.365  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:02:48.386  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:02:48.388  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:03:08.748  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:84}] to localhost:27017
2022-10-07 02:04:30.595  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:04:32.193  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:04:38.233  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:04:38.236  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:04:38.246  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:04:39.600  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:04:39.699  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 93 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:04:40.089  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:04:40.193  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:04:40.195  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:04:40.198  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:04:41.935  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@18b40fe6, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@7198ab9a], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@67d5ac2f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@25109608], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:04:42.055  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:04:42.259  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:04:44.085  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:85}] to localhost:27017
2022-10-07 02:04:44.085  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:86}] to localhost:27017
2022-10-07 02:04:44.086  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=79662600}
2022-10-07 02:04:46.559  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:04:48.285  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:04:48.398  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:04:48.498  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:04:48.544  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:04:48.549  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:04:48.577  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:04:48.577  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:04:48.578  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:04:48.578  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:04:48.579  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:04:48.579  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:04:48.579  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:04:48.964  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:04:48.969  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:04:48.972  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:04:48.979  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665126288978 with initial instances count: 5
2022-10-07 02:04:48.981  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:04:48.982  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665126288982, current=UP, previous=STARTING]
2022-10-07 02:04:48.985  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:04:49.032  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:04:49.044  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:04:49.133  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:04:49.133  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:04:49.137  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:04:49.137  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:04:49.137  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665126289134
2022-10-07 02:04:49.141  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:04:49.276  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:04:49.278  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:04:49.760  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:04:49.763  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:04:49.765  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:04:49.768  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:04:49.785  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:04:49.786  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:04:51.690  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 22.64 seconds (JVM running for 23.602)
2022-10-07 02:04:51.724  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=17, memberId='consumer-group_json-1-46bd1e9d-3a06-443b-b3cc-729ff50a4ec9', protocol='range'}
2022-10-07 02:04:51.927  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=17, memberId='consumer-group_json-1-46bd1e9d-3a06-443b-b3cc-729ff50a4ec9', protocol='range'}
2022-10-07 02:04:51.932  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:04:51.934  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:04:51.950  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:04:51.951  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:05:01.374  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:87}] to localhost:27017
2022-10-07 02:06:27.080  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:06:28.672  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:06:34.271  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:06:34.273  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:06:34.283  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:06:35.658  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:06:35.756  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 93 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:06:36.157  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:06:36.269  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:06:36.272  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:06:36.275  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:06:38.050  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:06:38.203  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:06:38.423  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:06:40.209  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:89}] to localhost:27017
2022-10-07 02:06:40.209  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:88}] to localhost:27017
2022-10-07 02:06:40.211  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=83633600}
2022-10-07 02:06:42.732  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:06:44.466  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:06:44.562  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:06:44.644  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:06:44.688  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:06:44.694  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:06:44.730  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:06:44.731  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:06:44.731  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:06:44.733  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:06:44.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:06:44.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:06:44.735  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:06:45.020  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:06:45.024  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:06:45.027  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:06:45.033  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665126405032 with initial instances count: 5
2022-10-07 02:06:45.034  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:06:45.035  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665126405035, current=UP, previous=STARTING]
2022-10-07 02:06:45.038  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:06:45.089  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:06:45.100  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:06:45.190  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:06:45.191  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:06:45.194  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:06:45.195  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:06:45.195  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665126405191
2022-10-07 02:06:45.200  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:06:45.324  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:06:45.326  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:06:45.607  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:06:45.610  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:06:45.612  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:06:45.616  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:06:45.633  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:06:45.634  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:06:47.546  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 22.017 seconds (JVM running for 22.955)
2022-10-07 02:06:48.766  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:90}] to localhost:27017
2022-10-07 02:06:49.007 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [5a1ccda0-1]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmitScalar(FluxFlatMap.java:488)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:421)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onNext(FluxUsingWhen.java:345)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:250)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:282)
		at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:863)
		at reactor.core.publisher.FluxConcatMap$WeakScalarSubscription.request(FluxConcatMap.java:479)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.set(Operators.java:2194)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:445)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:251)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:814)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:739)
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:161)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$recurseCursor$4(BatchCursorFlux.java:94)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:171)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onNext(FluxPeekFuseable.java:854)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.internal.operation.AsyncQueryBatchCursor.next(AsyncQueryBatchCursor.java:174)
		at com.mongodb.reactivestreams.client.internal.BatchCursor.lambda$next$0(BatchCursor.java:35)
		at reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:58)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.Mono.subscribeWith(Mono.java:4512)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4229)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.recurseCursor(BatchCursorFlux.java:104)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$subscribe$0(BatchCursorFlux.java:56)
		at reactor.core.publisher.LambdaMonoSubscriber.onNext(LambdaMonoSubscriber.java:171)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$2(OperationExecutorImpl.java:92)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.FindOperation$2.onResult(FindOperation.java:792)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$transformingReadCallback$10(CommandOperationHelper.java:331)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint ? Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint ? HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmitScalar(FluxFlatMap.java:488)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:421)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onNext(FluxUsingWhen.java:345)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:250)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:282)
		at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:863)
		at reactor.core.publisher.FluxConcatMap$WeakScalarSubscription.request(FluxConcatMap.java:479)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.set(Operators.java:2194)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:445)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:251)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:814)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:739)
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:161)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$recurseCursor$4(BatchCursorFlux.java:94)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:171)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onNext(FluxPeekFuseable.java:854)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.internal.operation.AsyncQueryBatchCursor.next(AsyncQueryBatchCursor.java:174)
		at com.mongodb.reactivestreams.client.internal.BatchCursor.lambda$next$0(BatchCursor.java:35)
		at reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:58)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.Mono.subscribeWith(Mono.java:4512)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4229)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.recurseCursor(BatchCursorFlux.java:104)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$subscribe$0(BatchCursorFlux.java:56)
		at reactor.core.publisher.LambdaMonoSubscriber.onNext(LambdaMonoSubscriber.java:171)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$2(OperationExecutorImpl.java:92)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.FindOperation$2.onResult(FindOperation.java:792)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$transformingReadCallback$10(CommandOperationHelper.java:331)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:266)
		at com.mongodb.internal.connection.InternalStreamConnection.readAsync(InternalStreamConnection.java:642)
		at com.mongodb.internal.connection.InternalStreamConnection.access$600(InternalStreamConnection.java:86)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:775)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback.onResult(InternalStreamConnection.java:760)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:06:51.959  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=18, memberId='consumer-group_json-1-92a91e21-8a73-4797-b619-d72b4660bda7', protocol='range'}
2022-10-07 02:06:51.973  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=18, memberId='consumer-group_json-1-92a91e21-8a73-4797-b619-d72b4660bda7', protocol='range'}
2022-10-07 02:06:51.978  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:06:51.982  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:06:52.005  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:06:52.006  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:07:16.837 ERROR LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] a.w.r.e.AbstractErrorWebExceptionHandler : [5a1ccda0-2]  500 Server Error for HTTP POST "/operation/accountClient/assignPrincipalAccount"
java.lang.ClassCastException: Cannot cast java.lang.IndexOutOfBoundsException to org.springframework.web.bind.support.WebExchangeBindException
	at java.base/java.lang.Class.cast(Class.java:3605)
	Suppressed: java.lang.IndexOutOfBoundsException: Source emitted more than one item
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmitScalar(FluxFlatMap.java:488)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:421)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onNext(FluxUsingWhen.java:345)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:250)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:282)
		at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:863)
		at reactor.core.publisher.FluxConcatMap$WeakScalarSubscription.request(FluxConcatMap.java:479)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.set(Operators.java:2194)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:445)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:251)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:814)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:739)
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:161)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$recurseCursor$4(BatchCursorFlux.java:94)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:171)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onNext(FluxPeekFuseable.java:854)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.internal.operation.AsyncQueryBatchCursor.next(AsyncQueryBatchCursor.java:174)
		at com.mongodb.reactivestreams.client.internal.BatchCursor.lambda$next$0(BatchCursor.java:35)
		at reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:58)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.Mono.subscribeWith(Mono.java:4512)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4229)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.recurseCursor(BatchCursorFlux.java:104)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$subscribe$0(BatchCursorFlux.java:56)
		at reactor.core.publisher.LambdaMonoSubscriber.onNext(LambdaMonoSubscriber.java:171)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$2(OperationExecutorImpl.java:92)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.FindOperation$2.onResult(FindOperation.java:792)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$transformingReadCallback$10(CommandOperationHelper.java:331)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: The stacktrace has been enhanced by Reactor, refer to additional information below: 
Error has been observed at the following site(s):
	*__checkpoint ? Handler nttdata.grupouno.com.operations.controllers.AccountClientController#assignPrincipalAccount(Mono) [DispatcherHandler]
	*__checkpoint ? org.springframework.boot.actuate.metrics.web.reactive.server.MetricsWebFilter [DefaultWebFilterChain]
	*__checkpoint ? HTTP POST "/operation/accountClient/assignPrincipalAccount" [ExceptionHandlingWebHandler]
Original Stack Trace:
		at java.base/java.lang.Class.cast(Class.java:3605)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onNext(FluxMapFuseable.java:113)
		at reactor.core.publisher.Operators$ScalarSubscription.request(Operators.java:2398)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.request(FluxMapFuseable.java:171)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onSubscribe(MonoFlatMap.java:110)
		at reactor.core.publisher.FluxMapFuseable$MapFuseableSubscriber.onSubscribe(FluxMapFuseable.java:96)
		at reactor.core.publisher.MonoJust.subscribe(MonoJust.java:55)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onError(FluxOnErrorResume.java:103)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.onError(Operators.java:2063)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.onError(MonoFlatMap.java:172)
		at reactor.core.publisher.MonoFlatMap$FlatMapMain.secondError(MonoFlatMap.java:192)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onError(MonoFlatMap.java:259)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onError(MonoSingle.java:150)
		at reactor.core.publisher.MonoSingle$SingleSubscriber.onNext(MonoSingle.java:134)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.tryEmitScalar(FluxFlatMap.java:488)
		at reactor.core.publisher.FluxFlatMap$FlatMapMain.onNext(FluxFlatMap.java:421)
		at reactor.core.publisher.FluxUsingWhen$UsingWhenSubscriber.onNext(FluxUsingWhen.java:345)
		at reactor.core.publisher.FluxOnErrorResume$ResumeSubscriber.onNext(FluxOnErrorResume.java:79)
		at reactor.core.publisher.MonoFlatMapMany$FlatMapManyInner.onNext(MonoFlatMapMany.java:250)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.innerNext(FluxConcatMap.java:282)
		at reactor.core.publisher.FluxConcatMap$ConcatMapInner.onNext(FluxConcatMap.java:863)
		at reactor.core.publisher.FluxConcatMap$WeakScalarSubscription.request(FluxConcatMap.java:479)
		at reactor.core.publisher.Operators$MultiSubscriptionSubscriber.set(Operators.java:2194)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.drain(FluxConcatMap.java:445)
		at reactor.core.publisher.FluxConcatMap$ConcatMapImmediate.onNext(FluxConcatMap.java:251)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.drain(FluxCreate.java:814)
		at reactor.core.publisher.FluxCreate$BufferAsyncSink.next(FluxCreate.java:739)
		at reactor.core.publisher.FluxCreate$SerializedFluxSink.next(FluxCreate.java:161)
		at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$recurseCursor$4(BatchCursorFlux.java:94)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:171)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.FluxPeekFuseable$PeekConditionalSubscriber.onNext(FluxPeekFuseable.java:854)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.internal.operation.AsyncQueryBatchCursor.next(AsyncQueryBatchCursor.java:174)
		at com.mongodb.reactivestreams.client.internal.BatchCursor.lambda$next$0(BatchCursor.java:35)
		at reactor.core.publisher.MonoCreate.subscribe(MonoCreate.java:58)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4397)
		at reactor.core.publisher.Mono.subscribeWith(Mono.java:4512)
		at reactor.core.publisher.Mono.subscribe(Mono.java:4229)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.recurseCursor(BatchCursorFlux.java:104)
		at com.mongodb.reactivestreams.client.internal.BatchCursorFlux.lambda$subscribe$0(BatchCursorFlux.java:56)
		at reactor.core.publisher.LambdaMonoSubscriber.onNext(LambdaMonoSubscriber.java:171)
		at reactor.core.publisher.FluxMap$MapSubscriber.onNext(FluxMap.java:122)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.MonoNext$NextSubscriber.onNext(MonoNext.java:82)
		at reactor.core.publisher.Operators$MonoSubscriber.complete(Operators.java:1816)
		at reactor.core.publisher.MonoFlatMap$FlatMapInner.onNext(MonoFlatMap.java:249)
		at reactor.core.publisher.MonoPeekTerminal$MonoTerminalPeekSubscriber.onNext(MonoPeekTerminal.java:180)
		at reactor.core.publisher.MonoCreate$DefaultMonoSink.success(MonoCreate.java:172)
		at com.mongodb.reactivestreams.client.internal.MongoOperationPublisher.lambda$sinkToCallback$30(MongoOperationPublisher.java:549)
		at com.mongodb.reactivestreams.client.internal.OperationExecutorImpl.lambda$execute$2(OperationExecutorImpl.java:92)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.function.RetryingAsyncCallbackSupplier$RetryingCallback.onResult(RetryingAsyncCallbackSupplier.java:114)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.async.function.AsyncCallbackSupplier.lambda$whenComplete$1(AsyncCallbackSupplier.java:95)
		at com.mongodb.internal.operation.FindOperation$2.onResult(FindOperation.java:792)
		at com.mongodb.internal.operation.CommandOperationHelper.lambda$transformingReadCallback$10(CommandOperationHelper.java:331)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.DefaultServer$DefaultServerProtocolExecutor$2.onResult(DefaultServer.java:276)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.CommandProtocolImpl$1.onResult(CommandProtocolImpl.java:84)
		at com.mongodb.internal.connection.DefaultConnectionPool$PooledConnection$1.onResult(DefaultConnectionPool.java:684)
		at com.mongodb.internal.connection.UsageTrackingInternalConnection$2.onResult(UsageTrackingInternalConnection.java:159)
		at com.mongodb.internal.async.ErrorHandlingResultCallback.onResult(ErrorHandlingResultCallback.java:48)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:521)
		at com.mongodb.internal.connection.InternalStreamConnection$2$1.onResult(InternalStreamConnection.java:498)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:821)
		at com.mongodb.internal.connection.InternalStreamConnection$MessageHeaderCallback$MessageCallback.onResult(InternalStreamConnection.java:785)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:645)
		at com.mongodb.internal.connection.InternalStreamConnection$5.completed(InternalStreamConnection.java:642)
		at com.mongodb.connection.netty.NettyStream.readAsync(NettyStream.java:319)
		at com.mongodb.connection.netty.NettyStream.handleReadResponse(NettyStream.java:347)
		at com.mongodb.connection.netty.NettyStream.access$1100(NettyStream.java:105)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:421)
		at com.mongodb.connection.netty.NettyStream$InboundBufferHandler.channelRead0(NettyStream.java:418)
		at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
		at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
		at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
		at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
		at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166)
		at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658)
		at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584)
		at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496)
		at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
		at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
		at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
		at java.base/java.lang.Thread.run(Thread.java:834)
2022-10-07 02:15:05.901  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:15:07.562  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:15:13.175  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:15:13.176  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:15:13.184  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:15:14.382  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:15:14.538  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 148 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:15:14.957  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:15:15.059  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:15:15.061  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:15:15.063  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:15:16.884  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:15:17.054  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:15:17.291  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:15:19.083  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:92}] to localhost:27017
2022-10-07 02:15:19.083  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:91}] to localhost:27017
2022-10-07 02:15:19.084  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=74613200}
2022-10-07 02:15:21.529  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:15:22.858  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:15:22.947  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:15:23.028  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:15:23.062  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:15:23.066  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:15:23.092  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:15:23.092  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:15:23.092  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:15:23.092  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:15:23.093  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:15:23.093  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:15:23.093  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:15:23.380  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:15:23.384  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:15:23.387  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:15:23.394  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665126923393 with initial instances count: 5
2022-10-07 02:15:23.396  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:15:23.396  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665126923396, current=UP, previous=STARTING]
2022-10-07 02:15:23.399  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:15:23.459  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:15:23.462  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:15:23.567  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:15:23.567  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:15:23.569  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:15:23.569  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:15:23.569  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665126923567
2022-10-07 02:15:23.573  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:15:23.658  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:15:23.660  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:15:24.022  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:15:24.026  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:15:24.029  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:15:24.032  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:15:24.054  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:15:24.055  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:15:25.902  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 21.733 seconds (JVM running for 22.807)
2022-10-07 02:15:26.545  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=20, memberId='consumer-group_json-1-de7167e3-f16e-4481-a389-85623e26659a', protocol='range'}
2022-10-07 02:15:26.935  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=20, memberId='consumer-group_json-1-de7167e3-f16e-4481-a389-85623e26659a', protocol='range'}
2022-10-07 02:15:26.941  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:15:26.945  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:15:26.962  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:15:26.964  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:18:19.531  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:18:21.053  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:18:23.292  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:18:23.294  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:18:23.302  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:18:24.514  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:18:24.612  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 92 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:18:25.089  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:18:25.276  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:18:25.278  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:18:25.281  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:18:27.004  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:18:27.130  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:18:27.367  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:18:29.197  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:93}] to localhost:27017
2022-10-07 02:18:29.197  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:94}] to localhost:27017
2022-10-07 02:18:29.199  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=78053600}
2022-10-07 02:18:31.173  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:18:32.528  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:18:32.625  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:18:32.708  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:18:32.748  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:18:32.754  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:18:32.777  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:18:32.777  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:18:32.778  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:18:32.778  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:18:32.778  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:18:32.778  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:18:32.778  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:18:33.068  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:18:33.072  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:18:33.076  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:18:33.082  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665127113081 with initial instances count: 5
2022-10-07 02:18:33.084  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:18:33.084  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665127113084, current=UP, previous=STARTING]
2022-10-07 02:18:33.087  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:18:33.128  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:18:33.150  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:18:33.223  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:18:33.223  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:18:33.226  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:18:33.226  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:18:33.226  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665127113224
2022-10-07 02:18:33.230  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:18:33.321  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:18:33.323  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:18:33.676  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:18:33.679  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:18:33.681  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:18:33.684  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:18:33.713  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:18:33.714  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:18:35.687  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 17.669 seconds (JVM running for 18.594)
2022-10-07 02:18:39.663  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:95}] to localhost:27017
2022-10-07 02:18:45.003  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=21, memberId='consumer-group_json-1-fd88dde5-e1f8-4404-90d4-661fa9b68063', protocol='range'}
2022-10-07 02:18:45.021  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=21, memberId='consumer-group_json-1-fd88dde5-e1f8-4404-90d4-661fa9b68063', protocol='range'}
2022-10-07 02:18:45.030  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:18:45.037  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:18:45.064  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:18:45.067  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:22:16.356  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:22:18.970  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:22:22.577  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:22:22.579  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:22:22.589  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:22:24.075  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:22:24.207  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 122 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:22:24.678  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:22:24.837  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:22:24.839  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:22:24.842  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:22:27.016  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@67d5ac2f, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@25109608], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1d637673]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@2913ca3e], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:22:27.191  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:22:27.467  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:22:30.136  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:96}] to localhost:27017
2022-10-07 02:22:30.136  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:97}] to localhost:27017
2022-10-07 02:22:30.138  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=123719100}
2022-10-07 02:22:33.232  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:22:35.547  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:22:35.678  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:22:35.805  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:22:35.861  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:22:35.869  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:22:35.906  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:22:35.907  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:22:35.907  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:22:35.908  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:22:35.908  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:22:35.909  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:22:35.909  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:22:36.357  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:22:36.363  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:22:36.368  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:22:36.377  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665127356375 with initial instances count: 5
2022-10-07 02:22:36.380  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:22:36.380  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665127356380, current=UP, previous=STARTING]
2022-10-07 02:22:36.384  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:22:36.449  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:22:36.461  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:22:36.601  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:22:36.602  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:22:36.607  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:22:36.607  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:22:36.608  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665127356602
2022-10-07 02:22:36.617  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:22:36.764  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:22:36.766  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:22:37.241  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:22:37.245  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:22:37.248  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:22:37.253  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:22:37.278  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:22:37.279  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:22:39.694  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=23, memberId='consumer-group_json-1-c64bc6ab-83b9-465c-941c-9bc0b284e3a0', protocol='range'}
2022-10-07 02:22:40.182  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=23, memberId='consumer-group_json-1-c64bc6ab-83b9-465c-941c-9bc0b284e3a0', protocol='range'}
2022-10-07 02:22:40.189  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:22:40.195  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:22:40.218  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:22:40.219  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:22:40.637  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 26.935 seconds (JVM running for 28.565)
2022-10-07 02:22:49.382  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:98}] to localhost:27017
2022-10-07 02:27:35.916  INFO LAPTOP-LTI5PG0G --- [trap-executor-0] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:28:49.490  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:28:52.025  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:29:03.444  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:29:03.447  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:29:03.460  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:29:05.131  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:29:05.275  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 136 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:29:05.769  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:29:05.898  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:29:05.900  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:29:05.903  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:29:07.976  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@7198ab9a, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@67d5ac2f], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@25109608]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@1d637673], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:29:08.162  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:29:08.440  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:29:10.873  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:99}] to localhost:27017
2022-10-07 02:29:10.873  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:100}] to localhost:27017
2022-10-07 02:29:10.874  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=98241100}
2022-10-07 02:29:13.944  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:29:16.317  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:29:16.501  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:29:16.632  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:29:16.689  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:29:16.696  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:29:16.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:29:16.734  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:29:16.735  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:29:16.735  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:29:16.735  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:29:16.735  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:29:16.736  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:29:17.206  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:29:17.212  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:29:17.217  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:29:17.226  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665127757225 with initial instances count: 5
2022-10-07 02:29:17.228  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:29:17.229  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665127757229, current=UP, previous=STARTING]
2022-10-07 02:29:17.233  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:29:17.307  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:29:17.323  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:29:17.481  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:29:17.482  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:29:17.486  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:29:17.487  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:29:17.487  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665127757482
2022-10-07 02:29:17.493  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:29:17.627  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:29:17.630  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:29:18.185  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:29:18.189  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:29:18.192  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:29:18.198  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:29:18.225  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:29:18.226  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:29:18.995  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:101}] to localhost:27017
2022-10-07 02:29:19.630  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=25, memberId='consumer-group_json-1-16ad6b7a-fe71-41af-a1a7-7efe33d89441', protocol='range'}
2022-10-07 02:29:19.839  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=25, memberId='consumer-group_json-1-16ad6b7a-fe71-41af-a1a7-7efe33d89441', protocol='range'}
2022-10-07 02:29:19.847  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:29:19.854  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:29:19.889  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:29:19.891  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:29:21.556  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 34.579 seconds (JVM running for 36.108)
2022-10-07 02:31:08.262  INFO LAPTOP-LTI5PG0G --- [kground-preinit] o.h.v.i.u.Version                        : HV000001: Hibernate Validator 6.2.4.Final
2022-10-07 02:31:10.805  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
2022-10-07 02:31:20.532  INFO LAPTOP-LTI5PG0G --- [           main] c.c.c.ConfigServicePropertySourceLocator : Located environment: name=operation-services, profiles=[default], label=null, version=dc23d83b8c5e446e973c0a1af85125c388a33986, state=null
2022-10-07 02:31:20.535  INFO LAPTOP-LTI5PG0G --- [           main] b.c.PropertySourceBootstrapConfiguration : Located property source: [BootstrapPropertySource {name='bootstrapProperties-configClient'}, BootstrapPropertySource {name='bootstrapProperties-https://github.com/FranciscoCY/Entregable_uno.git/file:C:\Users\DANIEL\AppData\Local\Temp\config-repo-15667010891174549500\Config-Data\operation-services.yml'}]
2022-10-07 02:31:20.545  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : No active profile set, falling back to 1 default profile: "default"
2022-10-07 02:31:22.133  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
2022-10-07 02:31:22.260  INFO LAPTOP-LTI5PG0G --- [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 120 ms. Found 6 Reactive MongoDB repository interfaces.
2022-10-07 02:31:22.738  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.c.s.GenericScope                   : BeanFactory id=faceba59-16a4-3e69-aead-2b2548bbc684
2022-10-07 02:31:22.861  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:31:22.864  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig' of type [org.springframework.cloud.client.loadbalancer.reactive.LoadBalancerBeanPostProcessorAutoConfiguration$ReactorDeferringLoadBalancerFilterConfig] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:31:22.867  INFO LAPTOP-LTI5PG0G --- [           main] trationDelegate$BeanPostProcessorChecker : Bean 'reactorDeferringLoadBalancerExchangeFilterFunction' of type [org.springframework.cloud.client.loadbalancer.reactive.DeferringLoadBalancerExchangeFilterFunction] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2022-10-07 02:31:24.936  INFO LAPTOP-LTI5PG0G --- [           main] o.m.d.client                             : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.6.1"}, "os": {"type": "Windows", "name": "Windows 10", "architecture": "amd64", "version": "10.0"}, "platform": "Java/Oracle Corporation/11.0.16.1+1-LTS-1"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=NettyStreamFactoryFactory{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@8851ec, socketChannelClass=class io.netty.channel.socket.nio.NioSocketChannel, allocator=PooledByteBufAllocator(directByDefault: true), sslContext=null}, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@18b40fe6], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7198ab9a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@67d5ac2f], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2022-10-07 02:31:25.113  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:31:25.397  WARN LAPTOP-LTI5PG0G --- [           main] o.s.d.c.CustomConversions                : Registering converter from class java.time.LocalDateTime to class org.joda.time.LocalDateTime as reading converter although it doesn't convert from a store-supported type; You might want to check your annotation setup at the converter implementation
2022-10-07 02:31:27.876  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:1, serverValue:102}] to localhost:27017
2022-10-07 02:31:27.876  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.connection                         : Opened connection [connectionId{localValue:2, serverValue:103}] to localhost:27017
2022-10-07 02:31:27.878  INFO LAPTOP-LTI5PG0G --- [localhost:27017] o.m.d.cluster                            : Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=101688300}
2022-10-07 02:31:30.816  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.a.e.w.EndpointLinksResolver        : Exposing 26 endpoint(s) beneath base path '/actuator'
2022-10-07 02:31:33.048  INFO LAPTOP-LTI5PG0G --- [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
2022-10-07 02:31:33.173  WARN LAPTOP-LTI5PG0G --- [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
2022-10-07 02:31:33.314  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.InstanceInfoFactory            : Setting initial instance status as: STARTING
2022-10-07 02:31:33.369  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Initializing Eureka in region us-east-1
2022-10-07 02:31:33.376  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.s.r.a.ConfigClusterResolver        : Resolving eureka endpoints via configuration
2022-10-07 02:31:33.410  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Disable delta property : false
2022-10-07 02:31:33.410  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Single vip registry refresh property : null
2022-10-07 02:31:33.410  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Force full registry fetch : false
2022-10-07 02:31:33.411  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application is null : false
2022-10-07 02:31:33.411  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Registered Applications size is zero : true
2022-10-07 02:31:33.411  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Application version is -1: true
2022-10-07 02:31:33.411  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Getting all instance registry info from the eureka server
2022-10-07 02:31:33.849  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : The response status is 200
2022-10-07 02:31:33.855  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Starting heartbeat executor: renew interval is: 30
2022-10-07 02:31:33.859  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.InstanceInfoReplicator             : InstanceInfoReplicator onDemand update allowed rate per min is 4
2022-10-07 02:31:33.867  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Discovery Client initialized at timestamp 1665127893866 with initial instances count: 5
2022-10-07 02:31:33.870  INFO LAPTOP-LTI5PG0G --- [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application OPERATION-SERVICES with eureka with status UP
2022-10-07 02:31:33.871  INFO LAPTOP-LTI5PG0G --- [           main] c.n.d.DiscoveryClient                    : Saw local status change event StatusChangeEvent [timestamp=1665127893871, current=UP, previous=STARTING]
2022-10-07 02:31:33.875  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010: registering service...
2022-10-07 02:31:33.934  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-group_json-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_json
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2022-10-07 02:31:33.946  INFO LAPTOP-LTI5PG0G --- [nfoReplicator-0] c.n.d.DiscoveryClient                    : DiscoveryClient_OPERATION-SERVICES/host.docker.internal:operation-services:8010 - registration status: 204
2022-10-07 02:31:34.071  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.trusted.packages' was supplied but isn't a known config.
2022-10-07 02:31:34.071  WARN LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.ConsumerConfig                 : The configuration 'spring.json.use.type.headers' was supplied but isn't a known config.
2022-10-07 02:31:34.075  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka version: 3.1.1
2022-10-07 02:31:34.076  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka commitId: 97671528ba54a138
2022-10-07 02:31:34.077  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.u.AppInfoParser                  : Kafka startTimeMs: 1665127894072
2022-10-07 02:31:34.083  INFO LAPTOP-LTI5PG0G --- [           main] o.a.k.c.c.KafkaConsumer                  : [Consumer clientId=consumer-group_json-1, groupId=group_json] Subscribed to topic(s): Kafka_target
2022-10-07 02:31:34.216  INFO LAPTOP-LTI5PG0G --- [           main] o.s.b.w.e.n.NettyWebServer               : Netty started on port 8010
2022-10-07 02:31:34.218  INFO LAPTOP-LTI5PG0G --- [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8010
2022-10-07 02:31:34.675  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Resetting the last seen epoch of partition Kafka_target-0 to 0 since the associated topicId changed from null to rCZmkVpeSJWPACPzIgwUgQ
2022-10-07 02:31:34.679  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.Metadata                         : [Consumer clientId=consumer-group_json-1, groupId=group_json] Cluster ID: 6TD1wq7pQOaINRYoUrvPvg
2022-10-07 02:31:34.682  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-10-07 02:31:34.687  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:31:34.712  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Request joining group due to: need to re-join with the given member-id
2022-10-07 02:31:34.713  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] (Re-)joining group
2022-10-07 02:31:35.003  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully joined group with generation Generation{generationId=27, memberId='consumer-group_json-1-41d5296c-01ba-473c-b872-7aa491ad1951', protocol='range'}
2022-10-07 02:31:35.334  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Successfully synced group in generation Generation{generationId=27, memberId='consumer-group_json-1-41d5296c-01ba-473c-b872-7aa491ad1951', protocol='range'}
2022-10-07 02:31:35.341  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Notifying assignor about the new Assignment(partitions=[Kafka_target-0])
2022-10-07 02:31:35.348  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Adding newly assigned partitions: Kafka_target-0
2022-10-07 02:31:35.370  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator          : [Consumer clientId=consumer-group_json-1, groupId=group_json] Setting offset for partition Kafka_target-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-10-07 02:31:35.372  INFO LAPTOP-LTI5PG0G --- [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : group_json: partitions assigned: [Kafka_target-0]
2022-10-07 02:31:37.786  INFO LAPTOP-LTI5PG0G --- [           main] n.g.c.o.OperationsApplication            : Started OperationsApplication in 32.042 seconds (JVM running for 33.582)
2022-10-07 02:32:20.807  INFO LAPTOP-LTI5PG0G --- [ntLoopGroup-3-3] o.m.d.connection                         : Opened connection [connectionId{localValue:3, serverValue:104}] to localhost:27017
